{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b22874",
   "metadata": {},
   "source": [
    "<h1>Artificial Neural Network (ANN) - Error, Loss এবং Cost Function এর গাণিতিক ব্যাখ্যা</h1>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>1. Error (ত্রুটি)</h2>\n",
    "<p>\n",
    "প্রত্যেকটি ইনপুট ডেটার জন্য মডেল যেই প্রেডিকশন করে এবং আসল মানের মধ্যে পার্থক্যই হলো <b>error</b>।\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "গণিতের ভাষায়:<br>\n",
    "<code>Error = Actual Value − Predicted Value</code><br>\n",
    "অথবা,<br>\n",
    "<code>e = y − ŷ</code>\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "  <li>y = আসল মান (actual label)</li>\n",
    "  <li>ŷ = পূর্বানুমান করা মান (predicted label)</li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>2. Loss Function (একটি স্যাম্পলের জন্য)</h2>\n",
    "<p>\n",
    "Loss function প্রতিটি স্যাম্পলের জন্য মডেলের পারফরম্যান্স পরিমাপ করে। এটি বলে দেয়, একটি ইনপুটে মডেল কতটা ভুল করেছে।\n",
    "</p>\n",
    "\n",
    "<h3>বিভিন্ন ধরনের Loss Function:</h3>\n",
    "\n",
    "<h4>ক. Regression এর জন্য (Mean Squared Error - MSE)</h4>\n",
    "<p>\n",
    "<code>Loss = (y − ŷ)<sup>2</sup></code>\n",
    "</p>\n",
    "\n",
    "<h4>খ. Classification এর জন্য (Binary Cross Entropy)</h4>\n",
    "<p>\n",
    "<code>\n",
    "Loss = − [ y * log(ŷ) + (1 − y) * log(1 − ŷ) ]\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "  <li>ŷ ∈ (0, 1)</li>\n",
    "  <li>y = 0 অথবা 1 (binary class)</li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>3. Cost Function (সব স্যাম্পলের জন্য গড়)</h2>\n",
    "<p>\n",
    "Cost function হলো সকল training স্যাম্পলের জন্য loss এর গড়। এটি মডেলকে অপটিমাইজ করার জন্য ব্যাকপ্রোপাগেশন ধাপে ব্যবহার করা হয়।\n",
    "</p>\n",
    "\n",
    "<h3>গণিতের প্রকাশ:</h3>\n",
    "\n",
    "<h4>Mean Squared Error (MSE):</h4>\n",
    "<p>\n",
    "<code>\n",
    "Cost = (1 / m) * Σ (y<sub>i</sub> − ŷ<sub>i</sub>)<sup>2</sup> <br>\n",
    "= (1 / m) * Σ (Error<sub>i</sub>)<sup>2</sup>\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "<h4>Binary Cross Entropy:</h4>\n",
    "<p>\n",
    "<code>\n",
    "Cost = (1 / m) * Σ [ − y<sub>i</sub> * log(ŷ<sub>i</sub>) − (1 − y<sub>i</sub>) * log(1 − ŷ<sub>i</sub>) ]\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "  <li>m = মোট training স্যাম্পলের সংখ্যা</li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>সারাংশ টেবিল</h2>\n",
    "\n",
    "<table border=\"1\" cellpadding=\"6\" cellspacing=\"0\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>উপাদান</th>\n",
    "      <th>বর্ণনা</th>\n",
    "      <th>গাণিতিক রূপ</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Error</td>\n",
    "      <td>একটি স্যাম্পলে পার্থক্য</td>\n",
    "      <td>e = y − ŷ</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Loss</td>\n",
    "      <td>একটি স্যাম্পলের জন্য ক্ষতি</td>\n",
    "      <td>(y − ŷ)<sup>2</sup> বা BCE ফর্মুলা</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Cost</td>\n",
    "      <td>সব স্যাম্পলের গড় লস</td>\n",
    "      <td>Cost = (1/m) * Σ Loss</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h2>উল্লেখযোগ্য বিষয়:</h2>\n",
    "<ul>\n",
    "  <li>Loss function বেছে নিতে হয় প্রজেক্টের ধরণ (classification / regression) অনুসারে।</li>\n",
    "  <li>Cost function-ই মূলত অপটিমাইজ করা হয় Gradient Descent দিয়ে।</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a209ed4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9ae5b50",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb210137",
   "metadata": {},
   "source": [
    "MSE use kora hoy continuous datar jonno <br>\n",
    "cross entropy use kora hoy categorical datar jono"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05962d5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
