{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1189d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0dfb1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "# ‡¶°‡ßá‡¶ü‡¶æ‡¶∏‡ßá‡¶ü ‡¶≤‡ßã‡¶°\n",
    "iris = sns.load_dataset('iris')\n",
    "\n",
    "# ‡¶á‡¶®‡¶™‡ßÅ‡¶ü ‡¶´‡¶ø‡¶ö‡¶æ‡¶∞‡¶ó‡ßÅ‡¶≤‡ßã‡¶ï‡ßá ‡¶ü‡ßá‡¶®‡¶∏‡¶∞‡ßá ‡¶∞‡ßÇ‡¶™‡¶æ‡¶®‡ßç‡¶§‡¶∞\n",
    "data = torch.tensor(iris[iris.columns[0:4]].values).float()  # üî∏ .float() ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßã dtype ‡¶Æ‡¶ø‡¶≤‡¶æ‡¶§‡ßá\n",
    "\n",
    "# ‡¶≤‡ßá‡¶¨‡ßá‡¶≤ ‡¶á‡¶®‡¶ø‡¶∂‡¶ø‡ßü‡¶æ‡¶≤‡¶æ‡¶á‡¶ú\n",
    "labels = torch.zeros(len(data), dtype=torch.long)\n",
    "\n",
    "# üî∏ spelling mistake ‡¶´‡¶ø‡¶ï‡ßç‡¶∏ ‡¶ï‡¶∞‡¶æ ‡¶π‡ßü‡ßá‡¶õ‡ßá: 'verginica' ‚Üí 'virginica'\n",
    "labels[iris.species == 'versicolor'] = 1\n",
    "labels[iris.species == 'virginica'] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "448c618d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11  12  13  14]\n",
      " [ 21  22  23  24]\n",
      " [ 31  32  33  34]\n",
      " [ 41  42  43  44]\n",
      " [ 51  52  53  54]\n",
      " [ 61  62  63  64]\n",
      " [ 71  72  73  74]\n",
      " [ 81  82  83  84]\n",
      " [ 91  92  93  94]\n",
      " [101 102 103 104]]\n",
      " \n",
      "[False False False False False  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "fakedata=np.tile(np.array([1,2,3,4]),(10,1)) + np.tile(10*np.arange(1,11),(4,1)).T\n",
    "fakelabels=np.arange(10)>4\n",
    "print(fakedata),print(' ')\n",
    "print(fakelabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7963a206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000002772F2A33A0>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "fakedataldr=DataLoader(fakedata,shuffle=True)\n",
    "print(fakedataldr)\n",
    "print(fakedataldr.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ea94853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[61, 62, 63, 64]]) torch.Size([1, 4])\n",
      "1 tensor([[71, 72, 73, 74]]) torch.Size([1, 4])\n",
      "2 tensor([[51, 52, 53, 54]]) torch.Size([1, 4])\n",
      "3 tensor([[21, 22, 23, 24]]) torch.Size([1, 4])\n",
      "4 tensor([[41, 42, 43, 44]]) torch.Size([1, 4])\n",
      "5 tensor([[81, 82, 83, 84]]) torch.Size([1, 4])\n",
      "6 tensor([[91, 92, 93, 94]]) torch.Size([1, 4])\n",
      "7 tensor([[101, 102, 103, 104]]) torch.Size([1, 4])\n",
      "8 tensor([[11, 12, 13, 14]]) torch.Size([1, 4])\n",
      "9 tensor([[31, 32, 33, 34]]) torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "for i,oneSample in enumerate(fakedataldr):\n",
    "    print(i,oneSample,oneSample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45fa4441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 11.,  12.,  13.,  14.],\n",
      "        [ 21.,  22.,  23.,  24.],\n",
      "        [ 31.,  32.,  33.,  34.],\n",
      "        [ 41.,  42.,  43.,  44.],\n",
      "        [ 51.,  52.,  53.,  54.],\n",
      "        [ 61.,  62.,  63.,  64.],\n",
      "        [ 71.,  72.,  73.,  74.],\n",
      "        [ 81.,  82.,  83.,  84.],\n",
      "        [ 91.,  92.,  93.,  94.],\n",
      "        [101., 102., 103., 104.]]), tensor([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.]))\n",
      " \n",
      "tensor([[91., 92., 93., 94.]]) tensor([1.])\n",
      "tensor([[71., 72., 73., 74.]]) tensor([1.])\n",
      "tensor([[11., 12., 13., 14.]]) tensor([0.])\n",
      "tensor([[51., 52., 53., 54.]]) tensor([0.])\n",
      "tensor([[61., 62., 63., 64.]]) tensor([1.])\n",
      "tensor([[31., 32., 33., 34.]]) tensor([0.])\n",
      "tensor([[81., 82., 83., 84.]]) tensor([1.])\n",
      "tensor([[21., 22., 23., 24.]]) tensor([0.])\n",
      "tensor([[41., 42., 43., 44.]]) tensor([0.])\n",
      "tensor([[101., 102., 103., 104.]]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "fakedataset=torch.utils.data.TensorDataset(torch.Tensor(fakedata),torch.Tensor(fakelabels))\n",
    "print(fakedataset.tensors),print(' ')\n",
    "fakedataLdr=DataLoader(fakedataset,shuffle=True)\n",
    "\n",
    "for dat,lab in fakedataLdr:\n",
    "    print(dat,lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10ca8d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data,train_labels,test_labels=train_test_split(fakedata,fakelabels,test_size=.2)\n",
    "\n",
    "train_data=torch.utils.data.TensorDataset(\n",
    "    torch.Tensor(train_data),torch.Tensor(train_labels)\n",
    ")\n",
    "\n",
    "test_data=torch.utils.data.TensorDataset(\n",
    "    torch.Tensor(test_data),torch.Tensor(test_labels)\n",
    ")\n",
    "\n",
    "train_loader=DataLoader(train_data,batch_size=4)\n",
    "test_loader=DataLoader(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3c4687a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "tensor([[41., 42., 43., 44.],\n",
      "        [11., 12., 13., 14.],\n",
      "        [91., 92., 93., 94.],\n",
      "        [61., 62., 63., 64.]]) tensor([0., 0., 1., 1.])\n",
      " \n",
      "tensor([[71., 72., 73., 74.],\n",
      "        [31., 32., 33., 34.],\n",
      "        [81., 82., 83., 84.],\n",
      "        [21., 22., 23., 24.]]) tensor([1., 0., 1., 0.])\n",
      " \n",
      "Testing Data\n",
      "tensor([[51., 52., 53., 54.]]) tensor([0.])\n",
      " \n",
      "tensor([[101., 102., 103., 104.]]) tensor([1.])\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print('Training Data')\n",
    "for batch,label in train_loader:\n",
    "    print(batch,label)\n",
    "    print(' ')\n",
    "\n",
    "print('Testing Data')\n",
    "for batch,label in test_loader:\n",
    "    print(batch,label)\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68122de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ‡¶°‡ßá‡¶ü‡¶æ split ‡¶ï‡¶∞‡¶æ\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.8)\n",
    "\n",
    "#  TensorDataset ‡¶§‡ßà‡¶∞‡¶ø (‡¶∏‡¶†‡¶ø‡¶ï‡¶≠‡¶æ‡¶¨‡ßá)\n",
    "train_data = TensorDataset(train_data, train_labels)\n",
    "test_data = TensorDataset(test_data, test_labels)\n",
    "\n",
    "# DataLoader ‡¶§‡ßà‡¶∞‡¶ø\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=12)\n",
    "test_loader = DataLoader(test_data, batch_size=test_data.tensors[0].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63306134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 4]) torch.Size([12])\n",
      "torch.Size([12, 4]) torch.Size([12])\n",
      "torch.Size([6, 4]) torch.Size([6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[6.3000, 2.3000, 4.4000, 1.3000],\n",
       "         [7.1000, 3.0000, 5.9000, 2.1000],\n",
       "         [5.4000, 3.7000, 1.5000, 0.2000],\n",
       "         [6.3000, 2.5000, 4.9000, 1.5000],\n",
       "         [6.7000, 3.3000, 5.7000, 2.1000],\n",
       "         [4.6000, 3.2000, 1.4000, 0.2000]]),\n",
       " tensor([1, 2, 0, 1, 2, 0]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for X,y in train_loader:\n",
    "    print(X.shape,y.shape)\n",
    "\n",
    "X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e08c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def createANewModel():\n",
    "    # üîπ Model Architecture\n",
    "    ANNiris = nn.Sequential(\n",
    "        nn.Linear(4, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 3),  # 3 classes for Iris dataset\n",
    "    )\n",
    "    model = createANewModel(dropoutRate=0.25)\n",
    "\n",
    "\n",
    "    # üîπ Loss Function (multi-class classification)\n",
    "    lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "    # üîπ Optimizer\n",
    "    optimizer = torch.optim.SGD(ANNiris.parameters(), lr=0.01)\n",
    "\n",
    "    return ANNiris, lossfun, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db022577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTheModel(model, lossfun, optimizer, train_loader, test_loader, numepochs=100):\n",
    "    trainAcc = []\n",
    "    testAcc = []\n",
    "\n",
    "    for epochi in range(numepochs):\n",
    "        batchAcc = []\n",
    "\n",
    "        # üîπ Training mode\n",
    "        model.train()\n",
    "        for X, y in train_loader:\n",
    "            yHat = model(X)\n",
    "            loss = lossfun(yHat, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accuracy calculation\n",
    "            preds = torch.argmax(yHat, axis=1)\n",
    "            acc = 100 * torch.mean((preds == y).float()).item()\n",
    "            batchAcc.append(acc)\n",
    "\n",
    "        trainAcc.append(np.mean(batchAcc))\n",
    "\n",
    "        # üîπ Evaluation mode\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            batchTestAcc = []\n",
    "            for Xtest, ytest in test_loader:\n",
    "                yPred = model(Xtest)\n",
    "                predsTest = torch.argmax(yPred, axis=1)\n",
    "                accTest = 100 * torch.mean((predsTest == ytest).float()).item()\n",
    "                batchTestAcc.append(accTest)\n",
    "\n",
    "            testAcc.append(np.mean(batchTestAcc))  # ‡¶ó‡ßú ‡¶®‡¶ø‡ßü‡ßá ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá\n",
    "\n",
    "    return trainAcc, testAcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73feee18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb24b7b6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce0217fe",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
